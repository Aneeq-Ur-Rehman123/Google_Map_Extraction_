{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5469ba005cae1bfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T13:40:42.278999600Z",
     "start_time": "2026-02-02T13:40:42.270950900Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from google.oauth2.service_account import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import google.auth\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaFileUpload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29a9d98233c1d659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T13:40:42.690540900Z",
     "start_time": "2026-02-02T13:40:42.628610Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 01:57:25,860 | INFO | Environment variables loaded successfully\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "GOOGLE_CREDS_JSON = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "GOOGLE_DRIVE_FOLDER_ID = os.getenv(\"GOOGLE_DRIVE_FOLDER_ID\")\n",
    "MAX_RETRIES = int(os.getenv(\"MAX_RETRIES\", 3))\n",
    "REQUEST_DELAY = int(os.getenv(\"REQUEST_DELAY\", 1))\n",
    "PAGE_START = 1\n",
    "SERPER_API_KEY_Headers ={\n",
    "            \"X-API-KEY\": SERPER_API_KEY,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "OPENROUTER_API_KEY_Headers={\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "model ='gpt-3.5-turbo'\n",
    "base_url=\"https://google.serper.dev/places\"\n",
    "logging.info(\"Environment variables loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b0f61b60de36c41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T13:40:43.051658300Z",
     "start_time": "2026-02-02T13:40:43.031347100Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_input_config():\n",
    "    config = {}\n",
    "\n",
    "    with open(\"input.txt\", \"r\") as file:\n",
    "        for line in file:\n",
    "            if \"=\" in line:\n",
    "                key, value = line.strip().split(\"=\", 1)\n",
    "                config[key] = value\n",
    "\n",
    "    BUSINESS_TYPE = config.get(\"BUSINESS_TYPE\")\n",
    "    COUNTRY = config.get(\"COUNTRY\")\n",
    "    ZIP_CODES = [z.strip() for z in config.get(\"ZIP_CODES\", \"\").split(\",\") if z.strip()]\n",
    "    Page_Start = int(config.get(\"PAGE_START\", 1))\n",
    "    Page_End = int(config.get(\"PAGE_END\"))\n",
    "\n",
    "    logging.info(f\"Business Type: {BUSINESS_TYPE}\")\n",
    "    logging.info(f\"Country: {COUNTRY}\")\n",
    "    logging.info(f\"ZIP Codes: {', '.join(ZIP_CODES)}\")\n",
    "    logging.info(f\"Pages: {Page_Start} to {Page_End}\")\n",
    "\n",
    "    return BUSINESS_TYPE, COUNTRY, ZIP_CODES, Page_Start, Page_End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc539d38b8dbb80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T13:40:43.678230900Z",
     "start_time": "2026-02-02T13:40:43.658468Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "91190a30f57d314f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T13:40:44.232442200Z",
     "start_time": "2026-02-02T13:40:44.208126600Z"
    }
   },
   "outputs": [],
   "source": [
    "def safe_post(url, headers, payload, retries=3, delay=2):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "\n",
    "            elif response.status_code in (401, 403):\n",
    "                logging.error(\n",
    "                    f\"API KEY ERROR ({response.status_code}): {response.text}\"\n",
    "                )\n",
    "                return None\n",
    "\n",
    "            else:\n",
    "                logging.warning(\n",
    "                    f\"Request failed ({response.status_code}): {response.text}\"\n",
    "                )\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.warning(f\"Request exception: {e}\")\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d2f604ed9ea3d655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T13:40:44.715278300Z",
     "start_time": "2026-02-02T13:40:44.683596Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_business_data(ZIP_CODES, Page_Start, Page_End, BUSINESS_TYPE, COUNTRY, all_businesses, seen_cids):\n",
    "    for zip_code in ZIP_CODES:\n",
    "\n",
    "        if not zip_code.isdigit():\n",
    "            logging.warning(f\"Invalid ZIP skipped: {zip_code}\")\n",
    "            continue\n",
    "\n",
    "        logging.info(f\"Processing ZIP: {zip_code}\")\n",
    "\n",
    "        for page in range(Page_Start, Page_End + 1):\n",
    "            payload = {\n",
    "                \"q\": BUSINESS_TYPE,\n",
    "                \"location\": f\"{zip_code}, {COUNTRY}\",\n",
    "                \"page\": page\n",
    "            }\n",
    "\n",
    "            headers = SERPER_API_KEY_Headers\n",
    "\n",
    "            data = safe_post(base_url, headers, payload)\n",
    "\n",
    "            if not data:\n",
    "                logging.warning(f\"No data returned for ZIP {zip_code} page {page}\")\n",
    "                break\n",
    "\n",
    "            places = data.get(\"places\", [])\n",
    "\n",
    "            if not places:\n",
    "                logging.info(\n",
    "                    f\"No places found on page {page} for ZIP {zip_code}, stopping pagination\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "            logging.info(f\"Found {len(places)} places on page {page} for ZIP {zip_code}\")\n",
    "\n",
    "            for place in places:\n",
    "                cid = place.get(\"cid\")\n",
    "\n",
    "                if not cid or cid in seen_cids:\n",
    "                    continue\n",
    "\n",
    "                seen_cids.add(cid)\n",
    "\n",
    "                all_businesses.append({\n",
    "                    \"Business Name\": place.get(\"title\"),\n",
    "                    \"Address\": place.get(\"address\"),\n",
    "                    \"Phone\": place.get(\"phoneNumber\"),\n",
    "                    \"Website\": place.get(\"website\"),\n",
    "                    \"Google Rating\": place.get(\"rating\"),\n",
    "                    \"Review Count\": place.get(\"ratingCount\"),\n",
    "                    \"Category\": place.get(\"category\"),\n",
    "                    \"Latitude\": place.get(\"latitude\"),\n",
    "                    \"Longitude\": place.get(\"longitude\"),\n",
    "                    \"CID\": cid,\n",
    "                    \"GMB URL\": f\"https://www.google.com/maps?cid={cid}\",\n",
    "                    \"Source ZIP\": zip_code,\n",
    "                    \"Source Query\": f\"{BUSINESS_TYPE} {COUNTRY} {zip_code}\",\n",
    "                    \"About\": \"\"\n",
    "                })\n",
    "\n",
    "            # time.sleep(REQUEST_DELAY)\n",
    "\n",
    "    logging.info(f\"Total unique businesses collected: {len(all_businesses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a5cd68dcd7aace8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T13:40:45.195998900Z",
     "start_time": "2026-02-02T13:40:45.188236700Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_ai_descriptions(all_businesses):\n",
    "    for business in all_businesses:\n",
    "        prompt = f\"\"\"\n",
    "        Write a short professional SEO-friendly description.\n",
    "        Name: {business['Business Name']}\n",
    "        Category: {business['Category']}\n",
    "        Address: {business['Address']}\n",
    "        Rating: {business['Google Rating']}\n",
    "        Reviews: {business['Review Count']}\n",
    "        \"\"\"\n",
    "        headers = OPENROUTER_API_KEY_Headers\n",
    "        payload = {\n",
    "            \"model\": f\"openai/{model}\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "        }\n",
    "        data = safe_post(\"https://openrouter.ai/api/v1/chat/completions\", headers, payload, retries=MAX_RETRIES,\n",
    "                         delay=REQUEST_DELAY)\n",
    "        if data and \"choices\" in data and len(data[\"choices\"]) > 0:\n",
    "            business[\"About\"] = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    logging.info(\"AI descriptions generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76cb60c04b1988ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T13:40:45.655672Z",
     "start_time": "2026-02-02T13:40:45.634435Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_csv_output(all_businesses):\n",
    "    OUTPUT_DIR = \"output\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    today = datetime.today().strftime(\"%Y%m%d\")\n",
    "    csv_path = os.path.join(OUTPUT_DIR, f\"Google_Map_Extraction_{today}.csv\")\n",
    "\n",
    "    df = pd.DataFrame(all_businesses)\n",
    "    df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    logging.info(f\"CSV created at: {csv_path} with {df.shape[0]} rows\")\n",
    "\n",
    "    return csv_path, df, OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e0ca88e58854414b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T13:40:46.202428300Z",
     "start_time": "2026-02-02T13:40:46.182059300Z"
    }
   },
   "outputs": [],
   "source": [
    "def upload_to_google_sheets(df):\n",
    "    SCOPES = [\n",
    "        \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "        \"https://www.googleapis.com/auth/drive\"\n",
    "    ]\n",
    "\n",
    "    creds = Credentials.from_service_account_file(os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"), scopes=SCOPES)\n",
    "    sheets_service = build(\"sheets\", \"v4\", credentials=creds)\n",
    "    drive_service = build(\"drive\", \"v3\", credentials=creds)\n",
    "\n",
    "    SPREADSHEET_NAME = f\"Google_Map_Extraction_\"\n",
    "    today = datetime.today().strftime(\"%Y%m%d\")\n",
    "    sheet_title = f\"{today}\"\n",
    "\n",
    "    response = drive_service.files().list(\n",
    "        q=f\"name='{SPREADSHEET_NAME}' and mimeType='application/vnd.google-apps.spreadsheet'\",\n",
    "        spaces=\"drive\"\n",
    "    ).execute()\n",
    "    files = response.get(\"files\", [])\n",
    "\n",
    "    if files:\n",
    "        spreadsheet_id = files[0][\"id\"]\n",
    "        logging.info(f\"Found existing spreadsheet: {SPREADSHEET_NAME}\")\n",
    "    else:\n",
    "        spreadsheet_body = {\n",
    "            'properties': {'title': SPREADSHEET_NAME},\n",
    "            'sheets': [{'properties': {'title': sheet_title}}]\n",
    "        }\n",
    "        spreadsheet = sheets_service.spreadsheets().create(body=spreadsheet_body).execute()\n",
    "        spreadsheet_id = spreadsheet[\"spreadsheetId\"]\n",
    "\n",
    "        permission = {'type': 'user', 'role': 'writer', 'emailAddress': creds.service_account_email}\n",
    "        drive_service.permissions().create(fileId=spreadsheet_id, body=permission).execute()\n",
    "\n",
    "        logging.info(f\"Spreadsheet created: {SPREADSHEET_NAME}\")\n",
    "\n",
    "    try:\n",
    "        sheets_service.spreadsheets().batchUpdate(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            body={\"requests\": [{\"addSheet\": {\"properties\": {\"title\": sheet_title}}}]}\n",
    "        ).execute()\n",
    "        logging.info(f\"Sheet created: {sheet_title}\")\n",
    "    except HttpError as e:\n",
    "        if \"already exists\" in str(e):\n",
    "            logging.info(f\"Sheet {sheet_title} already exists\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    existing_cids = set()\n",
    "    sheet_empty = True\n",
    "\n",
    "    try:\n",
    "        existing_data = sheets_service.spreadsheets().values().get(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f\"{sheet_title}!A2:Z\"\n",
    "        ).execute()\n",
    "\n",
    "        rows = existing_data.get(\"values\", [])\n",
    "        if rows:\n",
    "            sheet_empty = False\n",
    "\n",
    "        CID_COL_INDEX = df.columns.get_loc(\"CID\")\n",
    "\n",
    "        for row in rows:\n",
    "            if len(row) > CID_COL_INDEX:\n",
    "                cid = row[CID_COL_INDEX]\n",
    "                if cid:\n",
    "                    existing_cids.add(cid)\n",
    "\n",
    "        logging.info(f\"Loaded {len(existing_cids)} existing CIDs from sheet\")\n",
    "\n",
    "    except HttpError:\n",
    "        logging.warning(\"Sheet empty or unreadable, assuming no existing data\")\n",
    "\n",
    "    def clean_cell(cell):\n",
    "        if cell is None or (isinstance(cell, float) and pd.isna(cell)):\n",
    "            return None\n",
    "        if isinstance(cell, str):\n",
    "            cell = cell.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace('\"', \"'\")\n",
    "            if len(cell) > 50000:\n",
    "                cell = cell[:50000]\n",
    "            return cell\n",
    "        return cell\n",
    "\n",
    "    df_clean = pd.DataFrame(df).where(pd.notnull(df), None)\n",
    "    cleaned_values = [[clean_cell(cell) for cell in row] for row in df.values.tolist()]\n",
    "\n",
    "    filtered_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        cid = row[\"CID\"]\n",
    "        if cid not in existing_cids:\n",
    "            filtered_rows.append([clean_cell(cell) for cell in row.tolist()])\n",
    "        else:\n",
    "            logging.info(f\"Skipped duplicate CID {cid}\")\n",
    "\n",
    "    if not filtered_rows:\n",
    "        logging.info(\"No new records found. Nothing appended.\")\n",
    "    else:\n",
    "        if sheet_empty:\n",
    "            values = [df.columns.tolist()] + filtered_rows\n",
    "        else:\n",
    "            values = filtered_rows\n",
    "\n",
    "        body = {\"values\": values}\n",
    "        sheets_service.spreadsheets().values().append(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f\"{sheet_title}!A1\",\n",
    "            valueInputOption=\"RAW\",\n",
    "            insertDataOption=\"INSERT_ROWS\",\n",
    "            body=body\n",
    "        ).execute()\n",
    "        logging.info(f\"Appended {len(filtered_rows)} new records to Google Sheets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5a2622c3b75d659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T13:40:46.682829700Z",
     "start_time": "2026-02-02T13:40:46.668880500Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleanup_output_directory(OUTPUT_DIR):\n",
    "    \"\"\"Delete the output directory after successful processing\"\"\"\n",
    "    if os.path.exists(OUTPUT_DIR):\n",
    "        shutil.rmtree(OUTPUT_DIR)\n",
    "        logging.info(f\"{OUTPUT_DIR} deleted after successful processing\")\n",
    "    else:\n",
    "        logging.warning(f\"{OUTPUT_DIR} not found, nothing to delete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "42b0641491672fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T13:41:13.668803600Z",
     "start_time": "2026-02-02T13:40:47.320512800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 01:57:46,723 | INFO | Business Type: software house\n",
      "2026-02-07 01:57:46,724 | INFO | Country: USA\n",
      "2026-02-07 01:57:46,724 | INFO | ZIP Codes: 11223, 12345\n",
      "2026-02-07 01:57:46,725 | INFO | Pages: 1 to 2\n",
      "2026-02-07 01:57:46,725 | INFO | Processing ZIP: 11223\n",
      "2026-02-07 01:57:48,683 | INFO | Found 10 places on page 1 for ZIP 11223\n",
      "2026-02-07 01:57:50,209 | INFO | Found 10 places on page 2 for ZIP 11223\n",
      "2026-02-07 01:57:50,210 | INFO | Processing ZIP: 12345\n",
      "2026-02-07 01:57:51,667 | INFO | Found 10 places on page 1 for ZIP 12345\n",
      "2026-02-07 01:57:53,183 | INFO | Found 10 places on page 2 for ZIP 12345\n",
      "2026-02-07 01:57:53,184 | INFO | Total unique businesses collected: 40\n",
      "2026-02-07 01:59:54,040 | INFO | AI descriptions generated\n",
      "2026-02-07 01:59:54,048 | INFO | CSV created at: output\\Google_Map_Extraction_20260207.csv with 40 rows\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    all_businesses = []\n",
    "    seen_cids = set()\n",
    "\n",
    "    BUSINESS_TYPE, COUNTRY, ZIP_CODES, Page_Start, Page_End = load_input_config()\n",
    "\n",
    "    fetch_business_data(ZIP_CODES, Page_Start, Page_End, BUSINESS_TYPE, COUNTRY, all_businesses, seen_cids)\n",
    "\n",
    "    generate_ai_descriptions(all_businesses)\n",
    "\n",
    "    csv_path, df, OUTPUT_DIR = create_csv_output(all_businesses)\n",
    "\n",
    "    # upload_to_google_sheets(df)\n",
    "\n",
    "    # cleanup_output_directory(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55147baca6acdd30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T13:03:54.541062200Z",
     "start_time": "2026-02-02T13:03:54.522759700Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e01fd2db57eb997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
